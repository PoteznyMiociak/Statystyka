---
title: 'Descriptive Statistics'
subtitle: 'Bivariate Analysis'
date: "`r Sys.Date()`"
author: "Klaudia Aleksiejew, Tymon Bujny, Mateusz Barszczewski, Pawel Gallas"
output:
  html_document: 
    theme: cerulean
    highlight: textmate
    fontsize: 10pt
    toc: yes
    code_download: yes
    toc_float:
      collapsed: no
    df_print: default
    toc_depth: 5
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup,	message = FALSE,	warning = FALSE,	include = FALSE}
library(dplyr)
library(tidyverse)
library(HSAUR3)
library(haven)
library(ggplot2)
library(gridExtra)
library(ppcor) # this package computes partial and semipartial correlations.
library(ltm) # this package computes point-biserial correlations.
library(devtools) 
#install_github("markheckmann/ryouready") # please install package "ryouready" from github! (then # it)
library(ryouready) # this package computes nonlinear "eta" correlations.
library(GGally) # this package computes correlation matrix.
library(psych) # this package computes qualitative correlations.
library(DescTools) # this package computes qualitative correlations.
```


## Introduction

This is our first lab when we are considering 2 dimensions and instead of calculating univariate statistics by groups (or factors) of other variable - we will measure their common relationships based on co-variance and correlation coefficients. 

*Please be very careful when choosing the measure of correlation! In case of different measurument scales we have to recode one of the variables into weaker scale.

It would be nice to add some additional plots in the background. Feel free to add your own sections and use external packages.

## Data

This time we are going to use a typical credit scoring data with predefined "default" variables and personal demografic and income data. Please take a look closer at headers and descriptions of each variable.

```{r load-data, warning=TRUE, include=FALSE}
download.file("https://github.com/kflisikowski/ds/blob/master/bank_defaults.sav?raw=true", destfile ="bank_defaults.sav",mode="wb")
bank_defaults <- read_sav("bank_defaults.sav")
bank<-na.omit(bank_defaults)
bank$def<-as.factor(bank$default)
bank$educ<-as.factor(bank$ed)
```

## Scatterplots

First let's visualize our quantitative relationships using scatterplots. 

```{r echo=FALSE, warning=TRUE}
# Basic scatter plot


# Change the point size, and shape


```

You can also normalize the skewed distribution of incomes using log:

```{r echo=FALSE, warning=TRUE}
# Basic scatter plot with the log of income


```

We can add an estimated linear regression line:

```{r echo=FALSE, warning=TRUE}




```

## Scatterplots by groups 

We can finally see if there any differences between risk status:

```{r echo=FALSE, warning=TRUE}

library(ggplot2)

age_counts <- bank %>%
  group_by(age) %>%
  summarise(total_count = n(), def_count = sum(def == 1), default_count = sum(default == 1))

ggplot(age_counts, aes(x = age)) +
  geom_point(aes(y = total_count), color = "blue", size = 3) +
  geom_point(aes(y = def_count), color = "red", size = 4) +
  geom_point(aes(y = default_count), color = "green", size = 2) +
  labs(x = "Age", y = "Count", title = "All, previously defaulted and currently defaulted people count by age") +
  scale_y_continuous(labels = scales::comma)
```

We can also see more closely if there any differences between those two distributions adding their estimated density plots:

```{r echo=FALSE, warning=TRUE}
library(ggplot2)

ggplot(age_counts, aes(x = def_count)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(x = "Default Count", y = "Density", title = "Density plot of currently defaulted people Count")

ggplot(age_counts, aes(x = default_count)) +
  geom_density(fill = "green", alpha = 0.5) +
  labs(x = "Defaulted Count", y = "Density", title = "Density plot of previously defaulted people Count")
```

We can also put those plots together:

```{r echo=FALSE, warning=TRUE}
library(ggplot2)

ggplot(age_counts) +
  geom_density(aes(x = def_count, fill = "Currently Defaulted"), alpha = 0.5) +
  geom_density(aes(x = default_count, fill = "Previously Defaulted"), alpha = 0.5) +
  labs(x = "Count", y = "Density", 
       title = "Density plot of currently and previously defaulted people count") +
  scale_fill_manual(values = c("red", "green"))
```

## Correlation coefficients - Pearson's linear correlation

Ok, let's move to some calculations.
In R, we can use the cor() function. It takes three arguments and the method: cor(x, y, method)
For 2 quantitative data, with all assumptions met, we can calculate simple Pearson's coefficient of linear correlation:

```{r echo=FALSE, warning=TRUE}
bank$logincome <- log(bank$income)

correlation <- cor(bank$age, bank$logincome, method = "pearson")

print(correlation)
```

Ok, what about the percentage of the explained variability?

```{r echo=FALSE, warning=TRUE}

R_squared <- correlation^2

percentage_of_explained_variability <- R_squared * 100

percentage_of_explained_variability
```
So as we can see almost ??? of total log of incomes' variability is explained by differences in age. The rest (???) is probably explained by other factors.

## Partial and semipartial correlation 

The partial and semi-partial (also known as part) correlations are used to express the specific portion of variance explained by eliminating the effect of other variables when assessing the correlation between two variables.

Partial correlation holds constant one variable when computing the relations to others. Suppose we want to know the correlation between X and Y holding Z constant for both X and Y. That would be the partial correlation between X and Y controlling for Z. 

Semipartial correlation holds Z constant for either X or Y, but not both, so if we wanted to control X for Z, we could compute the semipartial correlation between X and Y holding Z constant for X.

Suppose we want to know the correlation between the log of income and age controlling for years of employment. How highly correlated are these after controlling for tenure? 

**There can be more than one control variable.

```{r echo=FALSE, warning=FALSE}
bank$logincome <- log(bank$income)

data <- data.frame(
  logincome = bank$logincome,
  age = bank$age,
  employ = bank$employ
)

result <- pcor(data)

#partial correlation
print(result$estimate["logincome", "age"])



```

How can we interpret the obtained partial correlation coefficient? What is the difference between that one and the semi-partial coefficient:

```{r echo=FALSE, warning=FALSE}
#linear model and its difference
first <- lm(logincome ~ employ, data = data)
residuals_logincome <- resid(first)

second <- lm(age ~ employ, data = data)
residuals_age <- resid(second)

semi_partial_corr <- cor(residuals_logincome, data$age)
print(semi_partial_corr)

#difference
print(result$estimate["logincome", "age"]-semi_partial_corr)


```

## Rank correlation 

For 2 different scales - like for example this pair of variables: income vs. education levels - we cannot use Pearson's coefficient. The only possibility is to rank also incomes... and lose some more detailed information about them. 

First, let's see boxplots of income by education levels.

```{r echo=FALSE, warning=TRUE}

bank %>%
    ggplot(aes(as.factor(ed), logincome)) + geom_boxplot()


```

Now, let's see Kendal's coefficient of rank correlation (robust for ties).

```{r echo=FALSE, warning=TRUE}
kendal <- cor(bank$income, bank$ed, method = "kendall")
print(kendal)

```


## Point-biserial correlation

Let's try to verify if there is a significant relationship between incomes and risk status. First, let's take a look at the boxplot:

```{r echo=FALSE, warning=TRUE}

bank %>%
    ggplot(aes(preddef1, logincome)) + geom_boxplot()

```

If you would like to compare 1 quantitative variable (income) and 1 dychotomous variable (default status - binary), then you can use point-biserial coefficient:

```{r echo=FALSE, warning=FALSE}
#i choose to compare def and income
point_bis <- cor(bank$income, as.numeric(bank$def), method = "pearson")
print(point_bis)

```


## Nonlinear correlation - eta coefficient

If you would like to check if there are any nonlinearities between 2 variables, the only possibility (beside transformations and linear analysis) is to calculate "eta" coefficient and compare it with the Pearson's linear coefficient. 

```{r echo=FALSE, warning=FALSE}
library(polycor)

eta <- eta(bank$age, bank$logincome)

# Calculate Pearson's correlation coefficient
pearson <- cor(bank$age, bank$logincome)

# Print the results
#print(eta)
print(pearson)


```

## Correlation matrix

We can also prepare the correlation matrix for all quantitative variables stored in our data frame. 

We can use ggcorr() function:

```{r echo=FALSE, warning=TRUE}

ggcorr(bank_defaults, method = c("everything", "pearson"))

```
  
As you can see - the default correlation matrix is not the best idea for all measurement scales (including binary variable "default"). 

That's why now we can perform our bivariate analysis with ggpair with grouping.

## Correlation matrix with scatterplots 

Here is what we are about to calculate:
- The correlation matrix between age, log_income, employ, address, debtinc, creddebt, and othdebt variable grouped by whether the person has a default status or not.
- Plot the distribution of each variable by group
- Display the scatter plot with the trend by group

```{r echo=FALSE, warning=TRUE}

# Select the variables of interest and ensure 'default' is included for grouping
selected_vars <- c('age', 'logincome', 'employ', 'address', 'debtinc', 'creddebt', 'othdebt', 'default')
bank_subset <- bank[, selected_vars]
bank_subset$default <- as.factor(bank_subset$default)


cor_matrix <- cor(bank_subset[, 1:7])
corrplot::corrplot(cor_matrix, method = "color")

library(reshape2)
bank_melted <- melt(bank_subset, id.vars = "default")
ggplot(bank_melted, aes(x = value, fill = default)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~variable, scales = "free") +
  theme_minimal()


ggpairs(data = bank_subset, 
        columns = 1:7,          
        aes(color = default),  
        diag = list(continuous = wrap("densityDiag", alpha = 0.5)),  
        lower = list(continuous = wrap("smooth", method = "lm", se = FALSE, size = 0.5)) 
       ) + 
  theme_bw()  


```


## Qualitative data

In case of two variables measured on nominal or ordinal&nominal scale - we are forced to organize so called "contingency" table with frequencies and calculate some kind of the correlation coefficient based on them. This is so called "contingency analysis". 

Let's consider one example based on our data: verify, if there is any significant correlation between education level and credit risk.

```{r}

library(gmodels)


table_bank <- table(bank$ed, bank$debtinc)

chi_test <- chisq.test(table_bank)
print(chi_test)


cramers_v <- sqrt(chi_test$statistic / (sum(table_bank) * (min(nrow(table_bank), ncol(table_bank)) - 1)))
print(cramers_v)
## The output from chisq.test will include a chi-squared statistic, degrees of freedom, and a p-value. A low p-value (typically < 0.05) suggests a significant association between education level and credit risk. The value of CramÃ©r's V ranges from 0 (no association) to 1 (perfect association), helping interpret the strength of the relationship.

```


## Exercise 1. Contingency analysis.

Do you believe in the Afterlife?
https://nationalpost.com/news/canada/millennials-do-you-believe-in-life-after-life
A survey was conducted and a random sample of 1091 questionnaires is given in the form of the following contingency table:

```{r echo=FALSE, warning=FALSE}
x=c(435,147,375,134)
dim(x)=c(2,2)
dane<-as.table(x)
dimnames(dane)=list(Gender=c('Female','Male'),Believe=c('Yes','No'))
dane
fourfoldplot(dane)
```

Our task is to check if there is a significant relationship between the belief in the afterlife and gender. We can perform this procedure with the simple chi-square statistics and chosen qualitative correlation coefficient (two-way 2x2 table).

```{r echo=FALSE, warning=FALSE}
yes<-c(435,147)
no<-c(375,134)
#cohen.kappa(cbind(yes,no))
chisq.test(dane)
prop.table(dane)
```

As you can see we can calculate our chi-square statistic really quickly for two-way tables or larger. 
Now we can standardize this contingency measure to see if the relationship is significant.

```{r echo=FALSE, warning=FALSE}
Phi(dane)
#?ContCoef
#ContCoef(dane)
#CramerV(dane)
#TschuprowT(dane)
mosaicplot(dane)
barplot(dane)
```


## Exercise 2. Contingency analysis for the 'Titanic' data.

Let's consider the titanic dataset which contains a complete list of passengers and crew members on the RMS Titanic. It includes a variable indicating whether a person did survive the sinking of the RMS Titanic on April 15, 1912.
A data frame contains 2456 observations on 14 variables.

```{r load-data2, warning=TRUE, include=FALSE}
download.file("https://github.com/kflisikowski/ds/blob/master/titanic.csv?raw=true", destfile ="titanic.csv",mode="wb")
titanic <- read.csv("titanic.csv",row.names=1,sep=";")
```

The website http://www.encyclopedia-titanica.org/ offers detailed information about passengers and crew members on the RMS Titanic. According to the website 1317 passengers and 890 crew member were aboard.

8 musicians and 9 employees of the shipyard company are listed as passengers, but travelled with a free ticket, which is why they have NA values in fare. In addition to that, fare is truely missing for a few regular passengers. 

```{r}
# your answer here

sum(is.na(titanic$Status))
sum(is.na(titanic$Class...Department))
sum(is.na(titanic$Gender))
sum(is.na(titanic$Embarked))

titanic_clean <- na.omit(titanic)

table_Class...Department_Survived <- table(titanic_clean$Class...Department, titanic_clean$Status)
print(table_Pclass_Survived)

table_Gender_Survived <- table(titanic_clean$Gender, titanic_clean$Status)
print(table_Sex_Survived)

table_Embarked_Survived <- table(titanic_clean$Embarked, titanic_clean$Status)
print(table_Embarked_Survived)

# Chi-square test for Class vs. Survival
chi_Class...Department_Survived <- chisq.test(table_Class...Department_Survived)
print(chi_Pclass_Survived)

# Chi-square test for Gender vs. Survival
chi_Gender_Survived <- chisq.test(table_Gender_Survived)
print(chi_Sex_Survived)

# Chi-square test for Embarked vs. Survival
chi_Embarked_Survived <- chisq.test(table_Embarked_Survived)
print(chi_Embarked_Survived)

```


